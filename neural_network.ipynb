{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN+NyFWRe3X/e47XAXDK3ZV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ginolaratro/LLM-projects/blob/main/neural_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSK6hkt3mgFk",
        "outputId": "a438d42c-52aa-44bf-db42-38c710e0933e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.2763 - loss: 1.1086\n",
            "Epoch 2/10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3429 - loss: 1.1022 \n",
            "Epoch 3/10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3209 - loss: 1.0997\n",
            "Epoch 4/10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.2863 - loss: 1.1041\n",
            "Epoch 5/10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3205 - loss: 1.0995\n",
            "Epoch 6/10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3320 - loss: 1.0980\n",
            "Epoch 7/10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3535 - loss: 1.0996\n",
            "Epoch 8/10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3378 - loss: 1.0965\n",
            "Epoch 9/10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3513 - loss: 1.0944\n",
            "Epoch 10/10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.3938 - loss: 1.0956\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7f79292d32c0>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Fake dataset\n",
        "# 100 samples, 4 features each\n",
        "X = np.random.rand(100, 4)\n",
        "\n",
        "# 3 classes (0, 1, 2)\n",
        "y = np.random.randint(0, 3, size=(100,))\n",
        "\n",
        "# Build model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(8, activation='relu', input_shape=(4,)),\n",
        "    tf.keras.layers.Dense(3)  # <- 3 outputs = 3 logits\n",
        "])\n",
        "\n",
        "# Compile\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Train\n",
        "model.fit(X, y, epochs=10)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-y6zJL1oKHb",
        "outputId": "7eb23919-0a6b-49e8-83da-251b688f8330"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.59455109, 0.09297815, 0.78743409, 0.08490913],\n",
              "       [0.82434318, 0.83552866, 0.3682319 , 0.77578502],\n",
              "       [0.47267006, 0.84834805, 0.55696681, 0.98466905],\n",
              "       [0.77185967, 0.89500357, 0.04069778, 0.16641197],\n",
              "       [0.77560737, 0.19604355, 0.82140162, 0.71919577],\n",
              "       [0.16634876, 0.94514934, 0.73647979, 0.12058142],\n",
              "       [0.48569275, 0.53951813, 0.40495994, 0.44572868],\n",
              "       [0.1682396 , 0.08077451, 0.86209302, 0.16174118],\n",
              "       [0.69208107, 0.6043585 , 0.78623047, 0.36185601],\n",
              "       [0.54486464, 0.47842145, 0.55151662, 0.70251362],\n",
              "       [0.58999854, 0.31693625, 0.63276763, 0.88390825],\n",
              "       [0.88331353, 0.88395552, 0.67680744, 0.74079422],\n",
              "       [0.58756076, 0.58073074, 0.67742973, 0.06449461],\n",
              "       [0.45954617, 0.6626138 , 0.07750123, 0.86144959],\n",
              "       [0.99794706, 0.19059556, 0.5885372 , 0.99939481],\n",
              "       [0.59284585, 0.2556106 , 0.45029435, 0.69505588],\n",
              "       [0.32663461, 0.49227349, 0.45669221, 0.57123094],\n",
              "       [0.82603208, 0.97828315, 0.22348034, 0.29334232],\n",
              "       [0.64999705, 0.24956973, 0.40879617, 0.78949597],\n",
              "       [0.30652695, 0.04289537, 0.6016984 , 0.58963657],\n",
              "       [0.2474397 , 0.19665215, 0.08336657, 0.63526364],\n",
              "       [0.26512008, 0.94542367, 0.11318334, 0.85298724],\n",
              "       [0.37012373, 0.31550344, 0.36449498, 0.4554523 ],\n",
              "       [0.78621743, 0.35295877, 0.61093287, 0.54906995],\n",
              "       [0.1459782 , 0.75252699, 0.88714062, 0.08880538],\n",
              "       [0.10019476, 0.44508069, 0.91119153, 0.58287268],\n",
              "       [0.3790013 , 0.8230092 , 0.16275387, 0.65107258],\n",
              "       [0.50124442, 0.46589369, 0.63085572, 0.52092596],\n",
              "       [0.98490424, 0.96026188, 0.45648836, 0.31623643],\n",
              "       [0.79949418, 0.76724265, 0.06693119, 0.4044506 ],\n",
              "       [0.39423373, 0.10804222, 0.12264406, 0.15061646],\n",
              "       [0.13059108, 0.94593822, 0.19839471, 0.61691962],\n",
              "       [0.04195401, 0.43150669, 0.964746  , 0.99395351],\n",
              "       [0.1713978 , 0.05784079, 0.54364568, 0.18248379],\n",
              "       [0.60147277, 0.1758971 , 0.80384736, 0.33744116],\n",
              "       [0.78692704, 0.41493294, 0.79415536, 0.67021542],\n",
              "       [0.23206913, 0.31154309, 0.46286978, 0.25825378],\n",
              "       [0.55472633, 0.15434229, 0.2220511 , 0.40176144],\n",
              "       [0.48886761, 0.3658994 , 0.64412057, 0.23772814],\n",
              "       [0.78789668, 0.28098921, 0.28599702, 0.22308614],\n",
              "       [0.63964062, 0.89898792, 0.86569042, 0.03344186],\n",
              "       [0.36127976, 0.56950672, 0.81032122, 0.92812024],\n",
              "       [0.49576309, 0.74594639, 0.35574263, 0.3803746 ],\n",
              "       [0.66336801, 0.17002015, 0.12756406, 0.61133709],\n",
              "       [0.24245398, 0.65412117, 0.71506823, 0.46383812],\n",
              "       [0.61902039, 0.29603516, 0.12342351, 0.50629342],\n",
              "       [0.57866902, 0.13903395, 0.95746146, 0.29384832],\n",
              "       [0.12713498, 0.45417156, 0.9094053 , 0.03622609],\n",
              "       [0.68229902, 0.98774963, 0.98235763, 0.7874118 ],\n",
              "       [0.71784051, 0.55857809, 0.06309306, 0.02598589],\n",
              "       [0.06724821, 0.50176255, 0.30068636, 0.70657912],\n",
              "       [0.19612401, 0.87824978, 0.02884857, 0.84122682],\n",
              "       [0.80729458, 0.62059076, 0.26936614, 0.47978695],\n",
              "       [0.45835651, 0.76034596, 0.90338867, 0.36096175],\n",
              "       [0.22110815, 0.32672324, 0.25479328, 0.34899262],\n",
              "       [0.90210401, 0.37961966, 0.35284406, 0.83262669],\n",
              "       [0.44798434, 0.01776807, 0.3323971 , 0.00392981],\n",
              "       [0.06218828, 0.20432839, 0.74795228, 0.02960444],\n",
              "       [0.07567958, 0.78524651, 0.45227424, 0.3957615 ],\n",
              "       [0.10176528, 0.44991566, 0.44000348, 0.57172395],\n",
              "       [0.82262747, 0.73682058, 0.94554498, 0.48031533],\n",
              "       [0.3071631 , 0.74213917, 0.75842441, 0.33599024],\n",
              "       [0.57222506, 0.53934396, 0.04005455, 0.82095469],\n",
              "       [0.94548823, 0.448394  , 0.78410572, 0.68534252],\n",
              "       [0.41524727, 0.64768036, 0.96298153, 0.07257066],\n",
              "       [0.65721661, 0.46748452, 0.80469173, 0.79472697],\n",
              "       [0.62317041, 0.31505217, 0.90704773, 0.96503356],\n",
              "       [0.91927846, 0.03241634, 0.51445564, 0.17768254],\n",
              "       [0.89143029, 0.81458896, 0.76900679, 0.21804227],\n",
              "       [0.67204692, 0.85813683, 0.29726207, 0.39868591],\n",
              "       [0.21506574, 0.9807846 , 0.24033891, 0.29118954],\n",
              "       [0.40302892, 0.59606518, 0.08200565, 0.4219443 ],\n",
              "       [0.32254015, 0.08701867, 0.12497964, 0.30529507],\n",
              "       [0.53263181, 0.04117261, 0.70836151, 0.07733214],\n",
              "       [0.12308261, 0.40366461, 0.93468409, 0.37568718],\n",
              "       [0.59729424, 0.89123111, 0.0741797 , 0.82750792],\n",
              "       [0.15527823, 0.61834262, 0.86236826, 0.06685687],\n",
              "       [0.00454726, 0.47508364, 0.38747857, 0.00645017],\n",
              "       [0.15457748, 0.38293638, 0.66338073, 0.42222729],\n",
              "       [0.84282152, 0.06399414, 0.851208  , 0.51590308],\n",
              "       [0.98287914, 0.53844992, 0.08555165, 0.91016434],\n",
              "       [0.18527906, 0.83405281, 0.9621762 , 0.88553541],\n",
              "       [0.67960474, 0.06350557, 0.94638639, 0.32929039],\n",
              "       [0.8537651 , 0.76226094, 0.90947256, 0.87128473],\n",
              "       [0.21651051, 0.14545507, 0.43518233, 0.706084  ],\n",
              "       [0.64097392, 0.25304193, 0.71401425, 0.74503522],\n",
              "       [0.8606965 , 0.14893915, 0.9969126 , 0.28805691],\n",
              "       [0.54109455, 0.49028612, 0.25534735, 0.36114986],\n",
              "       [0.48106569, 0.10626743, 0.08895334, 0.72379248],\n",
              "       [0.08606773, 0.60749596, 0.94589969, 0.50768633],\n",
              "       [0.60472719, 0.22895984, 0.88072133, 0.24821321],\n",
              "       [0.43892729, 0.31868163, 0.16980802, 0.33393703],\n",
              "       [0.789048  , 0.19705211, 0.87071939, 0.96512826],\n",
              "       [0.98539568, 0.90502766, 0.08613741, 0.94845526],\n",
              "       [0.96555775, 0.71951618, 0.57412458, 0.23454409],\n",
              "       [0.45282201, 0.98553473, 0.51028506, 0.74338393],\n",
              "       [0.16017092, 0.17068466, 0.83607831, 0.41877694],\n",
              "       [0.43904007, 0.58138395, 0.26976563, 0.43866048],\n",
              "       [0.91884858, 0.82008818, 0.2950805 , 0.62198619],\n",
              "       [0.89873214, 0.50235865, 0.81535433, 0.76390656]])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Load real handwritten digit data\n",
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vf-TCTfIoaVW",
        "outputId": "cf194621-c0b7-47ef-f97b-15156654bc89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)),  # turn image into 784 numbers\n",
        "    tf.keras.layers.Dense(128, activation='relu'),  # learn patterns\n",
        "    tf.keras.layers.Dense(10)  # 10 logits (for digits 0–9)\n",
        "])\n",
        "\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train, epochs=5)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqXLllx6oflR",
        "outputId": "3060acdd-e64b-4e67-c27e-87407b10ad01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.1078 - loss: 2.3018\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.1122 - loss: 2.3013\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.1133 - loss: 2.3014\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.1140 - loss: 2.3011\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.1119 - loss: 2.3013\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7f7924625c10>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test, y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_iemNvokrY-I",
        "outputId": "0f5f6d4f-1d99-4ad4-b563-c620e25595fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1160 - loss: 2.3013\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.301264762878418, 0.11349999904632568]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample = X_test[0:1]\n",
        "\n",
        "logits = model(sample)\n",
        "print(\"Logits:\", logits.numpy())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mi5jbXaLrecH",
        "outputId": "395ec50a-c31b-4deb-f845-203c086cd99f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logits: [[ 0.00197627  0.11738122 -0.03177003  0.0131141  -0.030847   -0.08435042\n",
            "  -0.00325851  0.03813067 -0.0354943  -0.02360712]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "probs = tf.nn.softmax(logits)\n",
        "\n",
        "print(\"Probabilities:\", probs.numpy())\n",
        "print(\"Predicted digit:\", np.argmax(probs))\n",
        "print(\"Actual digit:\", y_test[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WpXoaxkrlod",
        "outputId": "3c6af8a6-ab24-44db-d2da-4151d3cc2757"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Probabilities: [[0.10045296 0.11274116 0.09711961 0.10157804 0.09720929 0.09214496\n",
            "  0.09992848 0.10415123 0.09675858 0.09791563]]\n",
            "Predicted digit: 1\n",
            "Actual digit: 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logits are the raw, unnormalized output scores (ranging from \\(-\\infty \\) to \\(+\\infty \\)) from the final layer of a neural network before an activation function (like sigmoid or softmax) is applied. They represent the model's initial prediction confidence for classification tasks, where higher values indicate a higher likelihood for a class"
      ],
      "metadata": {
        "id": "zCTVJrc6sQTs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we will implement Cross-Entropy Loss.\n",
        "This will tell us how accurate our results are\n"
      ],
      "metadata": {
        "id": "rOurO_jlHJG6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np # Added for consistency, though not strictly needed for this specific loss calculation here.\n",
        "\n",
        "# The previous execution failed because 'y_test' and 'logits' were not defined in the current kernel session.\n",
        "# To demonstrate the cross-entropy loss calculation, we will re-initialize these variables\n",
        "# using the values that were successfully computed and displayed in previous cells.\n",
        "\n",
        "# Re-defining logits with the value obtained from `mi5jbXaLrecH`\n",
        "logits = tf.constant([[ 0.00197627,  0.11738122, -0.03177003,  0.0131141,  -0.030847,   -0.08435042,\n",
        "                      -0.00325851,  0.03813067, -0.0354943,  -0.02360712]], dtype=tf.float32)\n",
        "\n",
        "# Re-defining y_test[0] with the actual digit value obtained from `9WpXoaxkrlod`\n",
        "actual_digit = 7\n",
        "y_test_single_sample = tf.constant([actual_digit], dtype=tf.int32) # Needs to be a tensor with batch dimension\n",
        "\n",
        "# Calculate Sparse Categorical Crossentropy Loss for the sample\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "# Calculate the loss for the sample\n",
        "sample_loss = loss_object(y_test_single_sample, logits)\n",
        "\n",
        "print(f\"Logits for the sample: {logits.numpy().flatten()}\")\n",
        "print(f\"Actual digit for the sample: {actual_digit}\")\n",
        "print(f\"Calculated Sparse Categorical Crossentropy Loss: {sample_loss.numpy()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uLMO_lsGr8b",
        "outputId": "23258c59-be78-4be4-ff5e-966eba656be0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logits for the sample: [ 0.00197627  0.11738122 -0.03177003  0.0131141  -0.030847   -0.08435042\n",
            " -0.00325851  0.03813067 -0.0354943  -0.02360712]\n",
            "Actual digit for the sample: 7\n",
            "Calculated Sparse Categorical Crossentropy Loss: 2.261911153793335\n"
          ]
        }
      ]
    }
  ]
}